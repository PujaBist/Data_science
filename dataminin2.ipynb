{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95477ef4-966c-4363-a79b-bf6f0ed67b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\admin\\anaconda3\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\admin\\anaconda3\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\admin\\anaconda3\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from nltk) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in c:\\users\\admin\\anaconda3\\lib\\site-packages (from nltk) (4.66.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36fc72a7-014d-4b3c-9167-b0551876def4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('text_mining.txt' , 'r',encoding='utf-8') as file:\n",
    "    content=file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71c22363-4e07-4428-aa49-9363eed25716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial intelligence (AI) is the capability of computational systems to perform tasks typically associated with human intelligence, such as learning, reasoning, problem-solving, perception, and decision-making. It is a field of research in computer science that develops and studies methods and software that enable machines to perceive their environment and use learning and intelligence to take actions that maximize their chances of achieving defined goals.[1]\n",
      "\n",
      "High-profile applications of AI include advanced web search engines (e.g., Google Search); recommendation systems (used by YouTube, Amazon, and Netflix); virtual assistants (e.g., Google Assistant, Siri, and Alexa); autonomous vehicles (e.g., Waymo); generative and creative tools (e.g., language models and AI art); and superhuman play and analysis in strategy games (e.g., chess and Go). However, many AI applications are not perceived as AI: \"A lot of cutting edge AI has filtered into general applications, often without being called AI because once something becomes useful enough and common enough it's not labeled AI anymore.\"[2][3]\n",
      "\n",
      "Various subfields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include learning, reasoning, knowledge representation, planning, natural language processing, perception, and support for robotics.[a] To reach these goals, AI researchers have adapted and integrated a wide range of techniques, including search and mathematical optimization, formal logic, artificial neural networks, and methods based on statistics, operations research, and economics.[b] AI also draws upon psychology, linguistics, philosophy, neuroscience, and other fields.[4] Some companies, such as OpenAI, Google DeepMind and Meta,[5] aim to create artificial general intelligence (AGI)—AI that can complete virtually any cognitive task at least as well as a human.\n",
      "\n",
      "Artificial intelligence was founded as an academic discipline in 1956,[6] and the field went through multiple cycles of optimism throughout its history,[7][8] followed by periods of disappointment and loss of funding, known as AI winters.[9][10] Funding and interest vastly increased after 2012 when graphics processing units started being used to accelerate neural networks and deep learning outperformed previous AI techniques.[11] This growth accelerated further after 2017 with the transformer architecture.[12] In the 2020s, an ongoing period of rapid progress in advanced generative AI became known as the AI boom. Generative AI's ability to create and modify content has led to several unintended consequences and harms, while raising ethical concerns about AI's long-term effects and potential existential risks, prompting discussions about regulatory policies to ensure the safety and benefits of the technology.\n",
      "\n",
      "Goals\n",
      "The general problem of simulating (or creating) intelligence has been broken into subproblems. These consist of particular traits or capabilities that researchers expect an intelligent system to display. The traits described below have received the most attention and cover the scope of AI research.[a]\n",
      "\n",
      "Reasoning and problem-solving\n",
      "Early researchers developed algorithms that imitated step-by-step reasoning that humans use when they solve puzzles or make logical deductions.[13] By the late 1980s and 1990s, methods were developed for dealing with uncertain or incomplete information, employing concepts from probability and economics.[14]\n",
      "\n",
      "Many of these algorithms are insufficient for solving large reasoning problems because they experience a \"combinatorial explosion\": They become exponentially slower as the problems grow.[15] Even humans rarely use the step-by-step deduction that early AI research could model. They solve most of their problems using fast, intuitive judgments.[16] Accurate and efficient reasoning is an unsolved problem.\n"
     ]
    }
   ],
   "source": [
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "076045bc-d75f-4558-9812-c5339080dfc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pathlib in c:\\users\\admin\\anaconda3\\lib\\site-packages (1.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1e4d3bd-028f-4e42-9161-6787cc755b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b86bbbd-991a-44f4-ae5a-c345120f6eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "content=Path('text_mining.txt' ).read_text()  # another way to read the file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9be1b19b-8b09-43aa-8dfb-a35e22670d1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Artificial intelligence (AI) is the capability of computational systems to perform tasks typically associated with human intelligence, such as learning, reasoning, problem-solving, perception, and decision-making. It is a field of research in computer science that develops and studies methods and software that enable machines to perceive their environment and use learning and intelligence to take actions that maximize their chances of achieving defined goals.[1]\\n\\nHigh-profile applications of AI include advanced web search engines (e.g., Google Search); recommendation systems (used by YouTube, Amazon, and Netflix); virtual assistants (e.g., Google Assistant, Siri, and Alexa); autonomous vehicles (e.g., Waymo); generative and creative tools (e.g., language models and AI art); and superhuman play and analysis in strategy games (e.g., chess and Go). However, many AI applications are not perceived as AI: \"A lot of cutting edge AI has filtered into general applications, often without being called AI because once something becomes useful enough and common enough it\\'s not labeled AI anymore.\"[2][3]\\n\\nVarious subfields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include learning, reasoning, knowledge representation, planning, natural language processing, perception, and support for robotics.[a] To reach these goals, AI researchers have adapted and integrated a wide range of techniques, including search and mathematical optimization, formal logic, artificial neural networks, and methods based on statistics, operations research, and economics.[b] AI also draws upon psychology, linguistics, philosophy, neuroscience, and other fields.[4] Some companies, such as OpenAI, Google DeepMind and Meta,[5] aim to create artificial general intelligence (AGI)â€”AI that can complete virtually any cognitive task at least as well as a human.\\n\\nArtificial intelligence was founded as an academic discipline in 1956,[6] and the field went through multiple cycles of optimism throughout its history,[7][8] followed by periods of disappointment and loss of funding, known as AI winters.[9][10] Funding and interest vastly increased after 2012 when graphics processing units started being used to accelerate neural networks and deep learning outperformed previous AI techniques.[11] This growth accelerated further after 2017 with the transformer architecture.[12] In the 2020s, an ongoing period of rapid progress in advanced generative AI became known as the AI boom. Generative AI\\'s ability to create and modify content has led to several unintended consequences and harms, while raising ethical concerns about AI\\'s long-term effects and potential existential risks, prompting discussions about regulatory policies to ensure the safety and benefits of the technology.\\n\\nGoals\\nThe general problem of simulating (or creating) intelligence has been broken into subproblems. These consist of particular traits or capabilities that researchers expect an intelligent system to display. The traits described below have received the most attention and cover the scope of AI research.[a]\\n\\nReasoning and problem-solving\\nEarly researchers developed algorithms that imitated step-by-step reasoning that humans use when they solve puzzles or make logical deductions.[13] By the late 1980s and 1990s, methods were developed for dealing with uncertain or incomplete information, employing concepts from probability and economics.[14]\\n\\nMany of these algorithms are insufficient for solving large reasoning problems because they experience a \"combinatorial explosion\": They become exponentially slower as the problems grow.[15] Even humans rarely use the step-by-step deduction that early AI research could model. They solve most of their problems using fast, intuitive judgments.[16] Accurate and efficient reasoning is an unsolved problem.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d11d26-f4fb-41ac-8b2f-306285736d28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1beb0710-b462-46ef-ad02-bd5bfb0a6179",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad6786c-9856-4c41-a0b9-77423858dfa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3343c5-ff78-47d7-b90b-b322c34d4f6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15ba04e4-4dda-451d-a64b-44c2e05552ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenization\n",
    "# tokens=> each individual word "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12580949-961a-426d-9eee-605c12b36f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenization\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b12253e9-50b4-4c01-93bf-150fb77ec550",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d58412b9-35e6-4196-8cfc-d28f0564e1a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "859f6742-6469-4392-b091-fd47e1b0b140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Artificial', 'intelligence', '(', 'AI', ')', 'is', 'the', 'capability', 'of', 'computational', 'systems', 'to', 'perform', 'tasks', 'typically', 'associated', 'with', 'human', 'intelligence', ',', 'such', 'as', 'learning', ',', 'reasoning', ',', 'problem-solving', ',', 'perception', ',', 'and', 'decision-making', '.', 'It', 'is', 'a', 'field', 'of', 'research', 'in', 'computer', 'science', 'that', 'develops', 'and', 'studies', 'methods', 'and', 'software', 'that', 'enable', 'machines', 'to', 'perceive', 'their', 'environment', 'and', 'use', 'learning', 'and', 'intelligence', 'to', 'take', 'actions', 'that', 'maximize', 'their', 'chances', 'of', 'achieving', 'defined', 'goals', '.', '[', '1', ']', 'High-profile', 'applications', 'of', 'AI', 'include', 'advanced', 'web', 'search', 'engines', '(', 'e.g.', ',', 'Google', 'Search', ')', ';', 'recommendation', 'systems', '(', 'used', 'by', 'YouTube', ',', 'Amazon', ',', 'and', 'Netflix', ')', ';', 'virtual', 'assistants', '(', 'e.g.', ',', 'Google', 'Assistant', ',', 'Siri', ',', 'and', 'Alexa', ')', ';', 'autonomous', 'vehicles', '(', 'e.g.', ',', 'Waymo', ')', ';', 'generative', 'and', 'creative', 'tools', '(', 'e.g.', ',', 'language', 'models', 'and', 'AI', 'art', ')', ';', 'and', 'superhuman', 'play', 'and', 'analysis', 'in', 'strategy', 'games', '(', 'e.g.', ',', 'chess', 'and', 'Go', ')', '.', 'However', ',', 'many', 'AI', 'applications', 'are', 'not', 'perceived', 'as', 'AI', ':', '``', 'A', 'lot', 'of', 'cutting', 'edge', 'AI', 'has', 'filtered', 'into', 'general', 'applications', ',', 'often', 'without', 'being', 'called', 'AI', 'because', 'once', 'something', 'becomes', 'useful', 'enough', 'and', 'common', 'enough', 'it', \"'s\", 'not', 'labeled', 'AI', 'anymore', '.', '``', '[', '2', ']', '[', '3', ']', 'Various', 'subfields', 'of', 'AI', 'research', 'are', 'centered', 'around', 'particular', 'goals', 'and', 'the', 'use', 'of', 'particular', 'tools', '.', 'The', 'traditional', 'goals', 'of', 'AI', 'research', 'include', 'learning', ',', 'reasoning', ',', 'knowledge', 'representation', ',', 'planning', ',', 'natural', 'language', 'processing', ',', 'perception', ',', 'and', 'support', 'for', 'robotics', '.', '[', 'a', ']', 'To', 'reach', 'these', 'goals', ',', 'AI', 'researchers', 'have', 'adapted', 'and', 'integrated', 'a', 'wide', 'range', 'of', 'techniques', ',', 'including', 'search', 'and', 'mathematical', 'optimization', ',', 'formal', 'logic', ',', 'artificial', 'neural', 'networks', ',', 'and', 'methods', 'based', 'on', 'statistics', ',', 'operations', 'research', ',', 'and', 'economics', '.', '[', 'b', ']', 'AI', 'also', 'draws', 'upon', 'psychology', ',', 'linguistics', ',', 'philosophy', ',', 'neuroscience', ',', 'and', 'other', 'fields', '.', '[', '4', ']', 'Some', 'companies', ',', 'such', 'as', 'OpenAI', ',', 'Google', 'DeepMind', 'and', 'Meta', ',', '[', '5', ']', 'aim', 'to', 'create', 'artificial', 'general', 'intelligence', '(', 'AGI', ')', 'â€', '”', 'AI', 'that', 'can', 'complete', 'virtually', 'any', 'cognitive', 'task', 'at', 'least', 'as', 'well', 'as', 'a', 'human', '.', 'Artificial', 'intelligence', 'was', 'founded', 'as', 'an', 'academic', 'discipline', 'in', '1956', ',', '[', '6', ']', 'and', 'the', 'field', 'went', 'through', 'multiple', 'cycles', 'of', 'optimism', 'throughout', 'its', 'history', ',', '[', '7', ']', '[', '8', ']', 'followed', 'by', 'periods', 'of', 'disappointment', 'and', 'loss', 'of', 'funding', ',', 'known', 'as', 'AI', 'winters', '.', '[', '9', ']', '[', '10', ']', 'Funding', 'and', 'interest', 'vastly', 'increased', 'after', '2012', 'when', 'graphics', 'processing', 'units', 'started', 'being', 'used', 'to', 'accelerate', 'neural', 'networks', 'and', 'deep', 'learning', 'outperformed', 'previous', 'AI', 'techniques', '.', '[', '11', ']', 'This', 'growth', 'accelerated', 'further', 'after', '2017', 'with', 'the', 'transformer', 'architecture', '.', '[', '12', ']', 'In', 'the', '2020s', ',', 'an', 'ongoing', 'period', 'of', 'rapid', 'progress', 'in', 'advanced', 'generative', 'AI', 'became', 'known', 'as', 'the', 'AI', 'boom', '.', 'Generative', 'AI', \"'s\", 'ability', 'to', 'create', 'and', 'modify', 'content', 'has', 'led', 'to', 'several', 'unintended', 'consequences', 'and', 'harms', ',', 'while', 'raising', 'ethical', 'concerns', 'about', 'AI', \"'s\", 'long-term', 'effects', 'and', 'potential', 'existential', 'risks', ',', 'prompting', 'discussions', 'about', 'regulatory', 'policies', 'to', 'ensure', 'the', 'safety', 'and', 'benefits', 'of', 'the', 'technology', '.', 'Goals', 'The', 'general', 'problem', 'of', 'simulating', '(', 'or', 'creating', ')', 'intelligence', 'has', 'been', 'broken', 'into', 'subproblems', '.', 'These', 'consist', 'of', 'particular', 'traits', 'or', 'capabilities', 'that', 'researchers', 'expect', 'an', 'intelligent', 'system', 'to', 'display', '.', 'The', 'traits', 'described', 'below', 'have', 'received', 'the', 'most', 'attention', 'and', 'cover', 'the', 'scope', 'of', 'AI', 'research', '.', '[', 'a', ']', 'Reasoning', 'and', 'problem-solving', 'Early', 'researchers', 'developed', 'algorithms', 'that', 'imitated', 'step-by-step', 'reasoning', 'that', 'humans', 'use', 'when', 'they', 'solve', 'puzzles', 'or', 'make', 'logical', 'deductions', '.', '[', '13', ']', 'By', 'the', 'late', '1980s', 'and', '1990s', ',', 'methods', 'were', 'developed', 'for', 'dealing', 'with', 'uncertain', 'or', 'incomplete', 'information', ',', 'employing', 'concepts', 'from', 'probability', 'and', 'economics', '.', '[', '14', ']', 'Many', 'of', 'these', 'algorithms', 'are', 'insufficient', 'for', 'solving', 'large', 'reasoning', 'problems', 'because', 'they', 'experience', 'a', '``', 'combinatorial', 'explosion', \"''\", ':', 'They', 'become', 'exponentially', 'slower', 'as', 'the', 'problems', 'grow', '.', '[', '15', ']', 'Even', 'humans', 'rarely', 'use', 'the', 'step-by-step', 'deduction', 'that', 'early', 'AI', 'research', 'could', 'model', '.', 'They', 'solve', 'most', 'of', 'their', 'problems', 'using', 'fast', ',', 'intuitive', 'judgments', '.', '[', '16', ']', 'Accurate', 'and', 'efficient', 'reasoning', 'is', 'an', 'unsolved', 'problem', '.']\n"
     ]
    }
   ],
   "source": [
    "tokens=word_tokenize(content) # for tokenization\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1005e5a-484b-4f2c-86d3-c5e45e8e095f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shortcut way to tokenize\n",
    "tokens=content.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc48dd9e-8d73-4893-bfe0-f9802652b01f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Artificial',\n",
       " 'intelligence',\n",
       " '(AI)',\n",
       " 'is',\n",
       " 'the',\n",
       " 'capability',\n",
       " 'of',\n",
       " 'computational',\n",
       " 'systems',\n",
       " 'to',\n",
       " 'perform',\n",
       " 'tasks',\n",
       " 'typically',\n",
       " 'associated',\n",
       " 'with',\n",
       " 'human',\n",
       " 'intelligence,',\n",
       " 'such',\n",
       " 'as',\n",
       " 'learning,',\n",
       " 'reasoning,',\n",
       " 'problem-solving,',\n",
       " 'perception,',\n",
       " 'and',\n",
       " 'decision-making.',\n",
       " 'It',\n",
       " 'is',\n",
       " 'a',\n",
       " 'field',\n",
       " 'of',\n",
       " 'research',\n",
       " 'in',\n",
       " 'computer',\n",
       " 'science',\n",
       " 'that',\n",
       " 'develops',\n",
       " 'and',\n",
       " 'studies',\n",
       " 'methods',\n",
       " 'and',\n",
       " 'software',\n",
       " 'that',\n",
       " 'enable',\n",
       " 'machines',\n",
       " 'to',\n",
       " 'perceive',\n",
       " 'their',\n",
       " 'environment',\n",
       " 'and',\n",
       " 'use',\n",
       " 'learning',\n",
       " 'and',\n",
       " 'intelligence',\n",
       " 'to',\n",
       " 'take',\n",
       " 'actions',\n",
       " 'that',\n",
       " 'maximize',\n",
       " 'their',\n",
       " 'chances',\n",
       " 'of',\n",
       " 'achieving',\n",
       " 'defined',\n",
       " 'goals.[1]',\n",
       " 'High-profile',\n",
       " 'applications',\n",
       " 'of',\n",
       " 'AI',\n",
       " 'include',\n",
       " 'advanced',\n",
       " 'web',\n",
       " 'search',\n",
       " 'engines',\n",
       " '(e.g.,',\n",
       " 'Google',\n",
       " 'Search);',\n",
       " 'recommendation',\n",
       " 'systems',\n",
       " '(used',\n",
       " 'by',\n",
       " 'YouTube,',\n",
       " 'Amazon,',\n",
       " 'and',\n",
       " 'Netflix);',\n",
       " 'virtual',\n",
       " 'assistants',\n",
       " '(e.g.,',\n",
       " 'Google',\n",
       " 'Assistant,',\n",
       " 'Siri,',\n",
       " 'and',\n",
       " 'Alexa);',\n",
       " 'autonomous',\n",
       " 'vehicles',\n",
       " '(e.g.,',\n",
       " 'Waymo);',\n",
       " 'generative',\n",
       " 'and',\n",
       " 'creative',\n",
       " 'tools',\n",
       " '(e.g.,',\n",
       " 'language',\n",
       " 'models',\n",
       " 'and',\n",
       " 'AI',\n",
       " 'art);',\n",
       " 'and',\n",
       " 'superhuman',\n",
       " 'play',\n",
       " 'and',\n",
       " 'analysis',\n",
       " 'in',\n",
       " 'strategy',\n",
       " 'games',\n",
       " '(e.g.,',\n",
       " 'chess',\n",
       " 'and',\n",
       " 'Go).',\n",
       " 'However,',\n",
       " 'many',\n",
       " 'AI',\n",
       " 'applications',\n",
       " 'are',\n",
       " 'not',\n",
       " 'perceived',\n",
       " 'as',\n",
       " 'AI:',\n",
       " '\"A',\n",
       " 'lot',\n",
       " 'of',\n",
       " 'cutting',\n",
       " 'edge',\n",
       " 'AI',\n",
       " 'has',\n",
       " 'filtered',\n",
       " 'into',\n",
       " 'general',\n",
       " 'applications,',\n",
       " 'often',\n",
       " 'without',\n",
       " 'being',\n",
       " 'called',\n",
       " 'AI',\n",
       " 'because',\n",
       " 'once',\n",
       " 'something',\n",
       " 'becomes',\n",
       " 'useful',\n",
       " 'enough',\n",
       " 'and',\n",
       " 'common',\n",
       " 'enough',\n",
       " \"it's\",\n",
       " 'not',\n",
       " 'labeled',\n",
       " 'AI',\n",
       " 'anymore.\"[2][3]',\n",
       " 'Various',\n",
       " 'subfields',\n",
       " 'of',\n",
       " 'AI',\n",
       " 'research',\n",
       " 'are',\n",
       " 'centered',\n",
       " 'around',\n",
       " 'particular',\n",
       " 'goals',\n",
       " 'and',\n",
       " 'the',\n",
       " 'use',\n",
       " 'of',\n",
       " 'particular',\n",
       " 'tools.',\n",
       " 'The',\n",
       " 'traditional',\n",
       " 'goals',\n",
       " 'of',\n",
       " 'AI',\n",
       " 'research',\n",
       " 'include',\n",
       " 'learning,',\n",
       " 'reasoning,',\n",
       " 'knowledge',\n",
       " 'representation,',\n",
       " 'planning,',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'processing,',\n",
       " 'perception,',\n",
       " 'and',\n",
       " 'support',\n",
       " 'for',\n",
       " 'robotics.[a]',\n",
       " 'To',\n",
       " 'reach',\n",
       " 'these',\n",
       " 'goals,',\n",
       " 'AI',\n",
       " 'researchers',\n",
       " 'have',\n",
       " 'adapted',\n",
       " 'and',\n",
       " 'integrated',\n",
       " 'a',\n",
       " 'wide',\n",
       " 'range',\n",
       " 'of',\n",
       " 'techniques,',\n",
       " 'including',\n",
       " 'search',\n",
       " 'and',\n",
       " 'mathematical',\n",
       " 'optimization,',\n",
       " 'formal',\n",
       " 'logic,',\n",
       " 'artificial',\n",
       " 'neural',\n",
       " 'networks,',\n",
       " 'and',\n",
       " 'methods',\n",
       " 'based',\n",
       " 'on',\n",
       " 'statistics,',\n",
       " 'operations',\n",
       " 'research,',\n",
       " 'and',\n",
       " 'economics.[b]',\n",
       " 'AI',\n",
       " 'also',\n",
       " 'draws',\n",
       " 'upon',\n",
       " 'psychology,',\n",
       " 'linguistics,',\n",
       " 'philosophy,',\n",
       " 'neuroscience,',\n",
       " 'and',\n",
       " 'other',\n",
       " 'fields.[4]',\n",
       " 'Some',\n",
       " 'companies,',\n",
       " 'such',\n",
       " 'as',\n",
       " 'OpenAI,',\n",
       " 'Google',\n",
       " 'DeepMind',\n",
       " 'and',\n",
       " 'Meta,[5]',\n",
       " 'aim',\n",
       " 'to',\n",
       " 'create',\n",
       " 'artificial',\n",
       " 'general',\n",
       " 'intelligence',\n",
       " '(AGI)â€”AI',\n",
       " 'that',\n",
       " 'can',\n",
       " 'complete',\n",
       " 'virtually',\n",
       " 'any',\n",
       " 'cognitive',\n",
       " 'task',\n",
       " 'at',\n",
       " 'least',\n",
       " 'as',\n",
       " 'well',\n",
       " 'as',\n",
       " 'a',\n",
       " 'human.',\n",
       " 'Artificial',\n",
       " 'intelligence',\n",
       " 'was',\n",
       " 'founded',\n",
       " 'as',\n",
       " 'an',\n",
       " 'academic',\n",
       " 'discipline',\n",
       " 'in',\n",
       " '1956,[6]',\n",
       " 'and',\n",
       " 'the',\n",
       " 'field',\n",
       " 'went',\n",
       " 'through',\n",
       " 'multiple',\n",
       " 'cycles',\n",
       " 'of',\n",
       " 'optimism',\n",
       " 'throughout',\n",
       " 'its',\n",
       " 'history,[7][8]',\n",
       " 'followed',\n",
       " 'by',\n",
       " 'periods',\n",
       " 'of',\n",
       " 'disappointment',\n",
       " 'and',\n",
       " 'loss',\n",
       " 'of',\n",
       " 'funding,',\n",
       " 'known',\n",
       " 'as',\n",
       " 'AI',\n",
       " 'winters.[9][10]',\n",
       " 'Funding',\n",
       " 'and',\n",
       " 'interest',\n",
       " 'vastly',\n",
       " 'increased',\n",
       " 'after',\n",
       " '2012',\n",
       " 'when',\n",
       " 'graphics',\n",
       " 'processing',\n",
       " 'units',\n",
       " 'started',\n",
       " 'being',\n",
       " 'used',\n",
       " 'to',\n",
       " 'accelerate',\n",
       " 'neural',\n",
       " 'networks',\n",
       " 'and',\n",
       " 'deep',\n",
       " 'learning',\n",
       " 'outperformed',\n",
       " 'previous',\n",
       " 'AI',\n",
       " 'techniques.[11]',\n",
       " 'This',\n",
       " 'growth',\n",
       " 'accelerated',\n",
       " 'further',\n",
       " 'after',\n",
       " '2017',\n",
       " 'with',\n",
       " 'the',\n",
       " 'transformer',\n",
       " 'architecture.[12]',\n",
       " 'In',\n",
       " 'the',\n",
       " '2020s,',\n",
       " 'an',\n",
       " 'ongoing',\n",
       " 'period',\n",
       " 'of',\n",
       " 'rapid',\n",
       " 'progress',\n",
       " 'in',\n",
       " 'advanced',\n",
       " 'generative',\n",
       " 'AI',\n",
       " 'became',\n",
       " 'known',\n",
       " 'as',\n",
       " 'the',\n",
       " 'AI',\n",
       " 'boom.',\n",
       " 'Generative',\n",
       " \"AI's\",\n",
       " 'ability',\n",
       " 'to',\n",
       " 'create',\n",
       " 'and',\n",
       " 'modify',\n",
       " 'content',\n",
       " 'has',\n",
       " 'led',\n",
       " 'to',\n",
       " 'several',\n",
       " 'unintended',\n",
       " 'consequences',\n",
       " 'and',\n",
       " 'harms,',\n",
       " 'while',\n",
       " 'raising',\n",
       " 'ethical',\n",
       " 'concerns',\n",
       " 'about',\n",
       " \"AI's\",\n",
       " 'long-term',\n",
       " 'effects',\n",
       " 'and',\n",
       " 'potential',\n",
       " 'existential',\n",
       " 'risks,',\n",
       " 'prompting',\n",
       " 'discussions',\n",
       " 'about',\n",
       " 'regulatory',\n",
       " 'policies',\n",
       " 'to',\n",
       " 'ensure',\n",
       " 'the',\n",
       " 'safety',\n",
       " 'and',\n",
       " 'benefits',\n",
       " 'of',\n",
       " 'the',\n",
       " 'technology.',\n",
       " 'Goals',\n",
       " 'The',\n",
       " 'general',\n",
       " 'problem',\n",
       " 'of',\n",
       " 'simulating',\n",
       " '(or',\n",
       " 'creating)',\n",
       " 'intelligence',\n",
       " 'has',\n",
       " 'been',\n",
       " 'broken',\n",
       " 'into',\n",
       " 'subproblems.',\n",
       " 'These',\n",
       " 'consist',\n",
       " 'of',\n",
       " 'particular',\n",
       " 'traits',\n",
       " 'or',\n",
       " 'capabilities',\n",
       " 'that',\n",
       " 'researchers',\n",
       " 'expect',\n",
       " 'an',\n",
       " 'intelligent',\n",
       " 'system',\n",
       " 'to',\n",
       " 'display.',\n",
       " 'The',\n",
       " 'traits',\n",
       " 'described',\n",
       " 'below',\n",
       " 'have',\n",
       " 'received',\n",
       " 'the',\n",
       " 'most',\n",
       " 'attention',\n",
       " 'and',\n",
       " 'cover',\n",
       " 'the',\n",
       " 'scope',\n",
       " 'of',\n",
       " 'AI',\n",
       " 'research.[a]',\n",
       " 'Reasoning',\n",
       " 'and',\n",
       " 'problem-solving',\n",
       " 'Early',\n",
       " 'researchers',\n",
       " 'developed',\n",
       " 'algorithms',\n",
       " 'that',\n",
       " 'imitated',\n",
       " 'step-by-step',\n",
       " 'reasoning',\n",
       " 'that',\n",
       " 'humans',\n",
       " 'use',\n",
       " 'when',\n",
       " 'they',\n",
       " 'solve',\n",
       " 'puzzles',\n",
       " 'or',\n",
       " 'make',\n",
       " 'logical',\n",
       " 'deductions.[13]',\n",
       " 'By',\n",
       " 'the',\n",
       " 'late',\n",
       " '1980s',\n",
       " 'and',\n",
       " '1990s,',\n",
       " 'methods',\n",
       " 'were',\n",
       " 'developed',\n",
       " 'for',\n",
       " 'dealing',\n",
       " 'with',\n",
       " 'uncertain',\n",
       " 'or',\n",
       " 'incomplete',\n",
       " 'information,',\n",
       " 'employing',\n",
       " 'concepts',\n",
       " 'from',\n",
       " 'probability',\n",
       " 'and',\n",
       " 'economics.[14]',\n",
       " 'Many',\n",
       " 'of',\n",
       " 'these',\n",
       " 'algorithms',\n",
       " 'are',\n",
       " 'insufficient',\n",
       " 'for',\n",
       " 'solving',\n",
       " 'large',\n",
       " 'reasoning',\n",
       " 'problems',\n",
       " 'because',\n",
       " 'they',\n",
       " 'experience',\n",
       " 'a',\n",
       " '\"combinatorial',\n",
       " 'explosion\":',\n",
       " 'They',\n",
       " 'become',\n",
       " 'exponentially',\n",
       " 'slower',\n",
       " 'as',\n",
       " 'the',\n",
       " 'problems',\n",
       " 'grow.[15]',\n",
       " 'Even',\n",
       " 'humans',\n",
       " 'rarely',\n",
       " 'use',\n",
       " 'the',\n",
       " 'step-by-step',\n",
       " 'deduction',\n",
       " 'that',\n",
       " 'early',\n",
       " 'AI',\n",
       " 'research',\n",
       " 'could',\n",
       " 'model.',\n",
       " 'They',\n",
       " 'solve',\n",
       " 'most',\n",
       " 'of',\n",
       " 'their',\n",
       " 'problems',\n",
       " 'using',\n",
       " 'fast,',\n",
       " 'intuitive',\n",
       " 'judgments.[16]',\n",
       " 'Accurate',\n",
       " 'and',\n",
       " 'efficient',\n",
       " 'reasoning',\n",
       " 'is',\n",
       " 'an',\n",
       " 'unsolved',\n",
       " 'problem.']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68ed3e18-6fac-4d2c-a014-225cf9b19fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 350 samples and 544 outcomes>\n"
     ]
    }
   ],
   "source": [
    "# Most frequent /repeat of word\n",
    "from nltk.probability import FreqDist\n",
    "frequency=FreqDist(tokens)\n",
    "print(frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48877695-290e-469b-b664-2927d6e2c296",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens =544\n",
    "unique=350 \n",
    "=> meaning total word 504 ota xh tesma unique xae 350 word xh  aru baki sab word repeat vaako ho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e6dbbef2-a630-4885-adb4-eb5cd9c10ce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('and', 34),\n",
       " ('of', 19),\n",
       " ('AI', 16),\n",
       " ('the', 13),\n",
       " ('to', 9),\n",
       " ('as', 9),\n",
       " ('that', 8),\n",
       " ('intelligence', 5),\n",
       " ('(e.g.,', 5),\n",
       " ('a', 4)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequency.most_common(10) # 10 vaneko top 10 data dinxh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "42e208d7-e53b-4fe8-9472-0460b2031821",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Punctuation removal\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2682939d-184c-4ae4-bc4f-9e3fe151c547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f4a9053-f340-4de9-8cd0-f7d5c2a888d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "translator=str.maketrans('', '' , string.punctuation) #=> first space='' all token lai linch then it converts into second space=empty/null if it is present in string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dcc2ce91-43e4-4e8a-9808-5891ea3dda99",
   "metadata": {},
   "outputs": [],
   "source": [
    "after_content=content.translate(translator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "03b99f1e-ceaf-4819-977e-669475cfe016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Artificial intelligence AI is the capability of computational systems to perform tasks typically associated with human intelligence such as learning reasoning problemsolving perception and decisionmaking It is a field of research in computer science that develops and studies methods and software that enable machines to perceive their environment and use learning and intelligence to take actions that maximize their chances of achieving defined goals1\\n\\nHighprofile applications of AI include advanced web search engines eg Google Search recommendation systems used by YouTube Amazon and Netflix virtual assistants eg Google Assistant Siri and Alexa autonomous vehicles eg Waymo generative and creative tools eg language models and AI art and superhuman play and analysis in strategy games eg chess and Go However many AI applications are not perceived as AI A lot of cutting edge AI has filtered into general applications often without being called AI because once something becomes useful enough and common enough its not labeled AI anymore23\\n\\nVarious subfields of AI research are centered around particular goals and the use of particular tools The traditional goals of AI research include learning reasoning knowledge representation planning natural language processing perception and support for roboticsa To reach these goals AI researchers have adapted and integrated a wide range of techniques including search and mathematical optimization formal logic artificial neural networks and methods based on statistics operations research and economicsb AI also draws upon psychology linguistics philosophy neuroscience and other fields4 Some companies such as OpenAI Google DeepMind and Meta5 aim to create artificial general intelligence AGIâ€”AI that can complete virtually any cognitive task at least as well as a human\\n\\nArtificial intelligence was founded as an academic discipline in 19566 and the field went through multiple cycles of optimism throughout its history78 followed by periods of disappointment and loss of funding known as AI winters910 Funding and interest vastly increased after 2012 when graphics processing units started being used to accelerate neural networks and deep learning outperformed previous AI techniques11 This growth accelerated further after 2017 with the transformer architecture12 In the 2020s an ongoing period of rapid progress in advanced generative AI became known as the AI boom Generative AIs ability to create and modify content has led to several unintended consequences and harms while raising ethical concerns about AIs longterm effects and potential existential risks prompting discussions about regulatory policies to ensure the safety and benefits of the technology\\n\\nGoals\\nThe general problem of simulating or creating intelligence has been broken into subproblems These consist of particular traits or capabilities that researchers expect an intelligent system to display The traits described below have received the most attention and cover the scope of AI researcha\\n\\nReasoning and problemsolving\\nEarly researchers developed algorithms that imitated stepbystep reasoning that humans use when they solve puzzles or make logical deductions13 By the late 1980s and 1990s methods were developed for dealing with uncertain or incomplete information employing concepts from probability and economics14\\n\\nMany of these algorithms are insufficient for solving large reasoning problems because they experience a combinatorial explosion They become exponentially slower as the problems grow15 Even humans rarely use the stepbystep deduction that early AI research could model They solve most of their problems using fast intuitive judgments16 Accurate and efficient reasoning is an unsolved problem'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "after_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6eb5477-5411-4e32-a208-2cc678fbc7a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7afb6a0-8c1b-4521-a2cd-f61dc35ca04d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad79c623-8f44-4e90-a674-adeaaa359088",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2316d03e-c425-466e-8fd0-546153a28713",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stopwords Removal => a , an, the,... of, but"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0b1fd180-bb92-4e5a-9d66-16a304ff999e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.corpus # documnetation _collection= corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9f7d6404-b181-4d88-a696-92912435edc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ac57b680-33e9-4963-9d4c-5d233a4b2092",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "391e0e5a-f307-47cf-a72e-4fdc80637697",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words=set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e13694f3-8d87-40e4-a8cc-21956641c8fe",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " \"he'd\",\n",
       " \"he'll\",\n",
       " \"he's\",\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " \"i'd\",\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " \"i've\",\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it'd\",\n",
       " \"it'll\",\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she'd\",\n",
       " \"she'll\",\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " \"we'd\",\n",
       " \"we'll\",\n",
       " \"we're\",\n",
       " \"we've\",\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a55d44e-5851-4eba-ae24-f3fb33579425",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f985cc68-de0e-4d63-98cb-562f5ce447c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cc6f06-c97a-4804-8539-5d093f30e890",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "322095ee-5b30-4fa3-9bc0-87b399295915",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens=after_content.split() # Another way of tokenizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "90e9fac7-0bd8-4a04-833d-03fe4f892182",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Artificial',\n",
       " 'intelligence',\n",
       " 'AI',\n",
       " 'is',\n",
       " 'the',\n",
       " 'capability',\n",
       " 'of',\n",
       " 'computational',\n",
       " 'systems',\n",
       " 'to',\n",
       " 'perform',\n",
       " 'tasks',\n",
       " 'typically',\n",
       " 'associated',\n",
       " 'with',\n",
       " 'human',\n",
       " 'intelligence',\n",
       " 'such',\n",
       " 'as',\n",
       " 'learning',\n",
       " 'reasoning',\n",
       " 'problemsolving',\n",
       " 'perception',\n",
       " 'and',\n",
       " 'decisionmaking',\n",
       " 'It',\n",
       " 'is',\n",
       " 'a',\n",
       " 'field',\n",
       " 'of',\n",
       " 'research',\n",
       " 'in',\n",
       " 'computer',\n",
       " 'science',\n",
       " 'that',\n",
       " 'develops',\n",
       " 'and',\n",
       " 'studies',\n",
       " 'methods',\n",
       " 'and',\n",
       " 'software',\n",
       " 'that',\n",
       " 'enable',\n",
       " 'machines',\n",
       " 'to',\n",
       " 'perceive',\n",
       " 'their',\n",
       " 'environment',\n",
       " 'and',\n",
       " 'use',\n",
       " 'learning',\n",
       " 'and',\n",
       " 'intelligence',\n",
       " 'to',\n",
       " 'take',\n",
       " 'actions',\n",
       " 'that',\n",
       " 'maximize',\n",
       " 'their',\n",
       " 'chances',\n",
       " 'of',\n",
       " 'achieving',\n",
       " 'defined',\n",
       " 'goals1',\n",
       " 'Highprofile',\n",
       " 'applications',\n",
       " 'of',\n",
       " 'AI',\n",
       " 'include',\n",
       " 'advanced',\n",
       " 'web',\n",
       " 'search',\n",
       " 'engines',\n",
       " 'eg',\n",
       " 'Google',\n",
       " 'Search',\n",
       " 'recommendation',\n",
       " 'systems',\n",
       " 'used',\n",
       " 'by',\n",
       " 'YouTube',\n",
       " 'Amazon',\n",
       " 'and',\n",
       " 'Netflix',\n",
       " 'virtual',\n",
       " 'assistants',\n",
       " 'eg',\n",
       " 'Google',\n",
       " 'Assistant',\n",
       " 'Siri',\n",
       " 'and',\n",
       " 'Alexa',\n",
       " 'autonomous',\n",
       " 'vehicles',\n",
       " 'eg',\n",
       " 'Waymo',\n",
       " 'generative',\n",
       " 'and',\n",
       " 'creative',\n",
       " 'tools',\n",
       " 'eg',\n",
       " 'language',\n",
       " 'models',\n",
       " 'and',\n",
       " 'AI',\n",
       " 'art',\n",
       " 'and',\n",
       " 'superhuman',\n",
       " 'play',\n",
       " 'and',\n",
       " 'analysis',\n",
       " 'in',\n",
       " 'strategy',\n",
       " 'games',\n",
       " 'eg',\n",
       " 'chess',\n",
       " 'and',\n",
       " 'Go',\n",
       " 'However',\n",
       " 'many',\n",
       " 'AI',\n",
       " 'applications',\n",
       " 'are',\n",
       " 'not',\n",
       " 'perceived',\n",
       " 'as',\n",
       " 'AI',\n",
       " 'A',\n",
       " 'lot',\n",
       " 'of',\n",
       " 'cutting',\n",
       " 'edge',\n",
       " 'AI',\n",
       " 'has',\n",
       " 'filtered',\n",
       " 'into',\n",
       " 'general',\n",
       " 'applications',\n",
       " 'often',\n",
       " 'without',\n",
       " 'being',\n",
       " 'called',\n",
       " 'AI',\n",
       " 'because',\n",
       " 'once',\n",
       " 'something',\n",
       " 'becomes',\n",
       " 'useful',\n",
       " 'enough',\n",
       " 'and',\n",
       " 'common',\n",
       " 'enough',\n",
       " 'its',\n",
       " 'not',\n",
       " 'labeled',\n",
       " 'AI',\n",
       " 'anymore23',\n",
       " 'Various',\n",
       " 'subfields',\n",
       " 'of',\n",
       " 'AI',\n",
       " 'research',\n",
       " 'are',\n",
       " 'centered',\n",
       " 'around',\n",
       " 'particular',\n",
       " 'goals',\n",
       " 'and',\n",
       " 'the',\n",
       " 'use',\n",
       " 'of',\n",
       " 'particular',\n",
       " 'tools',\n",
       " 'The',\n",
       " 'traditional',\n",
       " 'goals',\n",
       " 'of',\n",
       " 'AI',\n",
       " 'research',\n",
       " 'include',\n",
       " 'learning',\n",
       " 'reasoning',\n",
       " 'knowledge',\n",
       " 'representation',\n",
       " 'planning',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " 'perception',\n",
       " 'and',\n",
       " 'support',\n",
       " 'for',\n",
       " 'roboticsa',\n",
       " 'To',\n",
       " 'reach',\n",
       " 'these',\n",
       " 'goals',\n",
       " 'AI',\n",
       " 'researchers',\n",
       " 'have',\n",
       " 'adapted',\n",
       " 'and',\n",
       " 'integrated',\n",
       " 'a',\n",
       " 'wide',\n",
       " 'range',\n",
       " 'of',\n",
       " 'techniques',\n",
       " 'including',\n",
       " 'search',\n",
       " 'and',\n",
       " 'mathematical',\n",
       " 'optimization',\n",
       " 'formal',\n",
       " 'logic',\n",
       " 'artificial',\n",
       " 'neural',\n",
       " 'networks',\n",
       " 'and',\n",
       " 'methods',\n",
       " 'based',\n",
       " 'on',\n",
       " 'statistics',\n",
       " 'operations',\n",
       " 'research',\n",
       " 'and',\n",
       " 'economicsb',\n",
       " 'AI',\n",
       " 'also',\n",
       " 'draws',\n",
       " 'upon',\n",
       " 'psychology',\n",
       " 'linguistics',\n",
       " 'philosophy',\n",
       " 'neuroscience',\n",
       " 'and',\n",
       " 'other',\n",
       " 'fields4',\n",
       " 'Some',\n",
       " 'companies',\n",
       " 'such',\n",
       " 'as',\n",
       " 'OpenAI',\n",
       " 'Google',\n",
       " 'DeepMind',\n",
       " 'and',\n",
       " 'Meta5',\n",
       " 'aim',\n",
       " 'to',\n",
       " 'create',\n",
       " 'artificial',\n",
       " 'general',\n",
       " 'intelligence',\n",
       " 'AGIâ€”AI',\n",
       " 'that',\n",
       " 'can',\n",
       " 'complete',\n",
       " 'virtually',\n",
       " 'any',\n",
       " 'cognitive',\n",
       " 'task',\n",
       " 'at',\n",
       " 'least',\n",
       " 'as',\n",
       " 'well',\n",
       " 'as',\n",
       " 'a',\n",
       " 'human',\n",
       " 'Artificial',\n",
       " 'intelligence',\n",
       " 'was',\n",
       " 'founded',\n",
       " 'as',\n",
       " 'an',\n",
       " 'academic',\n",
       " 'discipline',\n",
       " 'in',\n",
       " '19566',\n",
       " 'and',\n",
       " 'the',\n",
       " 'field',\n",
       " 'went',\n",
       " 'through',\n",
       " 'multiple',\n",
       " 'cycles',\n",
       " 'of',\n",
       " 'optimism',\n",
       " 'throughout',\n",
       " 'its',\n",
       " 'history78',\n",
       " 'followed',\n",
       " 'by',\n",
       " 'periods',\n",
       " 'of',\n",
       " 'disappointment',\n",
       " 'and',\n",
       " 'loss',\n",
       " 'of',\n",
       " 'funding',\n",
       " 'known',\n",
       " 'as',\n",
       " 'AI',\n",
       " 'winters910',\n",
       " 'Funding',\n",
       " 'and',\n",
       " 'interest',\n",
       " 'vastly',\n",
       " 'increased',\n",
       " 'after',\n",
       " '2012',\n",
       " 'when',\n",
       " 'graphics',\n",
       " 'processing',\n",
       " 'units',\n",
       " 'started',\n",
       " 'being',\n",
       " 'used',\n",
       " 'to',\n",
       " 'accelerate',\n",
       " 'neural',\n",
       " 'networks',\n",
       " 'and',\n",
       " 'deep',\n",
       " 'learning',\n",
       " 'outperformed',\n",
       " 'previous',\n",
       " 'AI',\n",
       " 'techniques11',\n",
       " 'This',\n",
       " 'growth',\n",
       " 'accelerated',\n",
       " 'further',\n",
       " 'after',\n",
       " '2017',\n",
       " 'with',\n",
       " 'the',\n",
       " 'transformer',\n",
       " 'architecture12',\n",
       " 'In',\n",
       " 'the',\n",
       " '2020s',\n",
       " 'an',\n",
       " 'ongoing',\n",
       " 'period',\n",
       " 'of',\n",
       " 'rapid',\n",
       " 'progress',\n",
       " 'in',\n",
       " 'advanced',\n",
       " 'generative',\n",
       " 'AI',\n",
       " 'became',\n",
       " 'known',\n",
       " 'as',\n",
       " 'the',\n",
       " 'AI',\n",
       " 'boom',\n",
       " 'Generative',\n",
       " 'AIs',\n",
       " 'ability',\n",
       " 'to',\n",
       " 'create',\n",
       " 'and',\n",
       " 'modify',\n",
       " 'content',\n",
       " 'has',\n",
       " 'led',\n",
       " 'to',\n",
       " 'several',\n",
       " 'unintended',\n",
       " 'consequences',\n",
       " 'and',\n",
       " 'harms',\n",
       " 'while',\n",
       " 'raising',\n",
       " 'ethical',\n",
       " 'concerns',\n",
       " 'about',\n",
       " 'AIs',\n",
       " 'longterm',\n",
       " 'effects',\n",
       " 'and',\n",
       " 'potential',\n",
       " 'existential',\n",
       " 'risks',\n",
       " 'prompting',\n",
       " 'discussions',\n",
       " 'about',\n",
       " 'regulatory',\n",
       " 'policies',\n",
       " 'to',\n",
       " 'ensure',\n",
       " 'the',\n",
       " 'safety',\n",
       " 'and',\n",
       " 'benefits',\n",
       " 'of',\n",
       " 'the',\n",
       " 'technology',\n",
       " 'Goals',\n",
       " 'The',\n",
       " 'general',\n",
       " 'problem',\n",
       " 'of',\n",
       " 'simulating',\n",
       " 'or',\n",
       " 'creating',\n",
       " 'intelligence',\n",
       " 'has',\n",
       " 'been',\n",
       " 'broken',\n",
       " 'into',\n",
       " 'subproblems',\n",
       " 'These',\n",
       " 'consist',\n",
       " 'of',\n",
       " 'particular',\n",
       " 'traits',\n",
       " 'or',\n",
       " 'capabilities',\n",
       " 'that',\n",
       " 'researchers',\n",
       " 'expect',\n",
       " 'an',\n",
       " 'intelligent',\n",
       " 'system',\n",
       " 'to',\n",
       " 'display',\n",
       " 'The',\n",
       " 'traits',\n",
       " 'described',\n",
       " 'below',\n",
       " 'have',\n",
       " 'received',\n",
       " 'the',\n",
       " 'most',\n",
       " 'attention',\n",
       " 'and',\n",
       " 'cover',\n",
       " 'the',\n",
       " 'scope',\n",
       " 'of',\n",
       " 'AI',\n",
       " 'researcha',\n",
       " 'Reasoning',\n",
       " 'and',\n",
       " 'problemsolving',\n",
       " 'Early',\n",
       " 'researchers',\n",
       " 'developed',\n",
       " 'algorithms',\n",
       " 'that',\n",
       " 'imitated',\n",
       " 'stepbystep',\n",
       " 'reasoning',\n",
       " 'that',\n",
       " 'humans',\n",
       " 'use',\n",
       " 'when',\n",
       " 'they',\n",
       " 'solve',\n",
       " 'puzzles',\n",
       " 'or',\n",
       " 'make',\n",
       " 'logical',\n",
       " 'deductions13',\n",
       " 'By',\n",
       " 'the',\n",
       " 'late',\n",
       " '1980s',\n",
       " 'and',\n",
       " '1990s',\n",
       " 'methods',\n",
       " 'were',\n",
       " 'developed',\n",
       " 'for',\n",
       " 'dealing',\n",
       " 'with',\n",
       " 'uncertain',\n",
       " 'or',\n",
       " 'incomplete',\n",
       " 'information',\n",
       " 'employing',\n",
       " 'concepts',\n",
       " 'from',\n",
       " 'probability',\n",
       " 'and',\n",
       " 'economics14',\n",
       " 'Many',\n",
       " 'of',\n",
       " 'these',\n",
       " 'algorithms',\n",
       " 'are',\n",
       " 'insufficient',\n",
       " 'for',\n",
       " 'solving',\n",
       " 'large',\n",
       " 'reasoning',\n",
       " 'problems',\n",
       " 'because',\n",
       " 'they',\n",
       " 'experience',\n",
       " 'a',\n",
       " 'combinatorial',\n",
       " 'explosion',\n",
       " 'They',\n",
       " 'become',\n",
       " 'exponentially',\n",
       " 'slower',\n",
       " 'as',\n",
       " 'the',\n",
       " 'problems',\n",
       " 'grow15',\n",
       " 'Even',\n",
       " 'humans',\n",
       " 'rarely',\n",
       " 'use',\n",
       " 'the',\n",
       " 'stepbystep',\n",
       " 'deduction',\n",
       " 'that',\n",
       " 'early',\n",
       " 'AI',\n",
       " 'research',\n",
       " 'could',\n",
       " 'model',\n",
       " 'They',\n",
       " 'solve',\n",
       " 'most',\n",
       " 'of',\n",
       " 'their',\n",
       " 'problems',\n",
       " 'using',\n",
       " 'fast',\n",
       " 'intuitive',\n",
       " 'judgments16',\n",
       " 'Accurate',\n",
       " 'and',\n",
       " 'efficient',\n",
       " 'reasoning',\n",
       " 'is',\n",
       " 'an',\n",
       " 'unsolved',\n",
       " 'problem']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dea01ead-0841-49d0-bbbe-8151a996894f",
   "metadata": {},
   "outputs": [],
   "source": [
    "after_stopwords=[]\n",
    "for word in tokens :\n",
    "    if word not in stop_words:\n",
    "        after_stopwords.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d0ee910e-641f-4e4d-90d2-bfc73408f4c4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Artificial',\n",
       " 'intelligence',\n",
       " 'AI',\n",
       " 'capability',\n",
       " 'computational',\n",
       " 'systems',\n",
       " 'perform',\n",
       " 'tasks',\n",
       " 'typically',\n",
       " 'associated',\n",
       " 'human',\n",
       " 'intelligence',\n",
       " 'learning',\n",
       " 'reasoning',\n",
       " 'problemsolving',\n",
       " 'perception',\n",
       " 'decisionmaking',\n",
       " 'It',\n",
       " 'field',\n",
       " 'research',\n",
       " 'computer',\n",
       " 'science',\n",
       " 'develops',\n",
       " 'studies',\n",
       " 'methods',\n",
       " 'software',\n",
       " 'enable',\n",
       " 'machines',\n",
       " 'perceive',\n",
       " 'environment',\n",
       " 'use',\n",
       " 'learning',\n",
       " 'intelligence',\n",
       " 'take',\n",
       " 'actions',\n",
       " 'maximize',\n",
       " 'chances',\n",
       " 'achieving',\n",
       " 'defined',\n",
       " 'goals1',\n",
       " 'Highprofile',\n",
       " 'applications',\n",
       " 'AI',\n",
       " 'include',\n",
       " 'advanced',\n",
       " 'web',\n",
       " 'search',\n",
       " 'engines',\n",
       " 'eg',\n",
       " 'Google',\n",
       " 'Search',\n",
       " 'recommendation',\n",
       " 'systems',\n",
       " 'used',\n",
       " 'YouTube',\n",
       " 'Amazon',\n",
       " 'Netflix',\n",
       " 'virtual',\n",
       " 'assistants',\n",
       " 'eg',\n",
       " 'Google',\n",
       " 'Assistant',\n",
       " 'Siri',\n",
       " 'Alexa',\n",
       " 'autonomous',\n",
       " 'vehicles',\n",
       " 'eg',\n",
       " 'Waymo',\n",
       " 'generative',\n",
       " 'creative',\n",
       " 'tools',\n",
       " 'eg',\n",
       " 'language',\n",
       " 'models',\n",
       " 'AI',\n",
       " 'art',\n",
       " 'superhuman',\n",
       " 'play',\n",
       " 'analysis',\n",
       " 'strategy',\n",
       " 'games',\n",
       " 'eg',\n",
       " 'chess',\n",
       " 'Go',\n",
       " 'However',\n",
       " 'many',\n",
       " 'AI',\n",
       " 'applications',\n",
       " 'perceived',\n",
       " 'AI',\n",
       " 'A',\n",
       " 'lot',\n",
       " 'cutting',\n",
       " 'edge',\n",
       " 'AI',\n",
       " 'filtered',\n",
       " 'general',\n",
       " 'applications',\n",
       " 'often',\n",
       " 'without',\n",
       " 'called',\n",
       " 'AI',\n",
       " 'something',\n",
       " 'becomes',\n",
       " 'useful',\n",
       " 'enough',\n",
       " 'common',\n",
       " 'enough',\n",
       " 'labeled',\n",
       " 'AI',\n",
       " 'anymore23',\n",
       " 'Various',\n",
       " 'subfields',\n",
       " 'AI',\n",
       " 'research',\n",
       " 'centered',\n",
       " 'around',\n",
       " 'particular',\n",
       " 'goals',\n",
       " 'use',\n",
       " 'particular',\n",
       " 'tools',\n",
       " 'The',\n",
       " 'traditional',\n",
       " 'goals',\n",
       " 'AI',\n",
       " 'research',\n",
       " 'include',\n",
       " 'learning',\n",
       " 'reasoning',\n",
       " 'knowledge',\n",
       " 'representation',\n",
       " 'planning',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " 'perception',\n",
       " 'support',\n",
       " 'roboticsa',\n",
       " 'To',\n",
       " 'reach',\n",
       " 'goals',\n",
       " 'AI',\n",
       " 'researchers',\n",
       " 'adapted',\n",
       " 'integrated',\n",
       " 'wide',\n",
       " 'range',\n",
       " 'techniques',\n",
       " 'including',\n",
       " 'search',\n",
       " 'mathematical',\n",
       " 'optimization',\n",
       " 'formal',\n",
       " 'logic',\n",
       " 'artificial',\n",
       " 'neural',\n",
       " 'networks',\n",
       " 'methods',\n",
       " 'based',\n",
       " 'statistics',\n",
       " 'operations',\n",
       " 'research',\n",
       " 'economicsb',\n",
       " 'AI',\n",
       " 'also',\n",
       " 'draws',\n",
       " 'upon',\n",
       " 'psychology',\n",
       " 'linguistics',\n",
       " 'philosophy',\n",
       " 'neuroscience',\n",
       " 'fields4',\n",
       " 'Some',\n",
       " 'companies',\n",
       " 'OpenAI',\n",
       " 'Google',\n",
       " 'DeepMind',\n",
       " 'Meta5',\n",
       " 'aim',\n",
       " 'create',\n",
       " 'artificial',\n",
       " 'general',\n",
       " 'intelligence',\n",
       " 'AGIâ€”AI',\n",
       " 'complete',\n",
       " 'virtually',\n",
       " 'cognitive',\n",
       " 'task',\n",
       " 'least',\n",
       " 'well',\n",
       " 'human',\n",
       " 'Artificial',\n",
       " 'intelligence',\n",
       " 'founded',\n",
       " 'academic',\n",
       " 'discipline',\n",
       " '19566',\n",
       " 'field',\n",
       " 'went',\n",
       " 'multiple',\n",
       " 'cycles',\n",
       " 'optimism',\n",
       " 'throughout',\n",
       " 'history78',\n",
       " 'followed',\n",
       " 'periods',\n",
       " 'disappointment',\n",
       " 'loss',\n",
       " 'funding',\n",
       " 'known',\n",
       " 'AI',\n",
       " 'winters910',\n",
       " 'Funding',\n",
       " 'interest',\n",
       " 'vastly',\n",
       " 'increased',\n",
       " '2012',\n",
       " 'graphics',\n",
       " 'processing',\n",
       " 'units',\n",
       " 'started',\n",
       " 'used',\n",
       " 'accelerate',\n",
       " 'neural',\n",
       " 'networks',\n",
       " 'deep',\n",
       " 'learning',\n",
       " 'outperformed',\n",
       " 'previous',\n",
       " 'AI',\n",
       " 'techniques11',\n",
       " 'This',\n",
       " 'growth',\n",
       " 'accelerated',\n",
       " '2017',\n",
       " 'transformer',\n",
       " 'architecture12',\n",
       " 'In',\n",
       " '2020s',\n",
       " 'ongoing',\n",
       " 'period',\n",
       " 'rapid',\n",
       " 'progress',\n",
       " 'advanced',\n",
       " 'generative',\n",
       " 'AI',\n",
       " 'became',\n",
       " 'known',\n",
       " 'AI',\n",
       " 'boom',\n",
       " 'Generative',\n",
       " 'AIs',\n",
       " 'ability',\n",
       " 'create',\n",
       " 'modify',\n",
       " 'content',\n",
       " 'led',\n",
       " 'several',\n",
       " 'unintended',\n",
       " 'consequences',\n",
       " 'harms',\n",
       " 'raising',\n",
       " 'ethical',\n",
       " 'concerns',\n",
       " 'AIs',\n",
       " 'longterm',\n",
       " 'effects',\n",
       " 'potential',\n",
       " 'existential',\n",
       " 'risks',\n",
       " 'prompting',\n",
       " 'discussions',\n",
       " 'regulatory',\n",
       " 'policies',\n",
       " 'ensure',\n",
       " 'safety',\n",
       " 'benefits',\n",
       " 'technology',\n",
       " 'Goals',\n",
       " 'The',\n",
       " 'general',\n",
       " 'problem',\n",
       " 'simulating',\n",
       " 'creating',\n",
       " 'intelligence',\n",
       " 'broken',\n",
       " 'subproblems',\n",
       " 'These',\n",
       " 'consist',\n",
       " 'particular',\n",
       " 'traits',\n",
       " 'capabilities',\n",
       " 'researchers',\n",
       " 'expect',\n",
       " 'intelligent',\n",
       " 'system',\n",
       " 'display',\n",
       " 'The',\n",
       " 'traits',\n",
       " 'described',\n",
       " 'received',\n",
       " 'attention',\n",
       " 'cover',\n",
       " 'scope',\n",
       " 'AI',\n",
       " 'researcha',\n",
       " 'Reasoning',\n",
       " 'problemsolving',\n",
       " 'Early',\n",
       " 'researchers',\n",
       " 'developed',\n",
       " 'algorithms',\n",
       " 'imitated',\n",
       " 'stepbystep',\n",
       " 'reasoning',\n",
       " 'humans',\n",
       " 'use',\n",
       " 'solve',\n",
       " 'puzzles',\n",
       " 'make',\n",
       " 'logical',\n",
       " 'deductions13',\n",
       " 'By',\n",
       " 'late',\n",
       " '1980s',\n",
       " '1990s',\n",
       " 'methods',\n",
       " 'developed',\n",
       " 'dealing',\n",
       " 'uncertain',\n",
       " 'incomplete',\n",
       " 'information',\n",
       " 'employing',\n",
       " 'concepts',\n",
       " 'probability',\n",
       " 'economics14',\n",
       " 'Many',\n",
       " 'algorithms',\n",
       " 'insufficient',\n",
       " 'solving',\n",
       " 'large',\n",
       " 'reasoning',\n",
       " 'problems',\n",
       " 'experience',\n",
       " 'combinatorial',\n",
       " 'explosion',\n",
       " 'They',\n",
       " 'become',\n",
       " 'exponentially',\n",
       " 'slower',\n",
       " 'problems',\n",
       " 'grow15',\n",
       " 'Even',\n",
       " 'humans',\n",
       " 'rarely',\n",
       " 'use',\n",
       " 'stepbystep',\n",
       " 'deduction',\n",
       " 'early',\n",
       " 'AI',\n",
       " 'research',\n",
       " 'could',\n",
       " 'model',\n",
       " 'They',\n",
       " 'solve',\n",
       " 'problems',\n",
       " 'using',\n",
       " 'fast',\n",
       " 'intuitive',\n",
       " 'judgments16',\n",
       " 'Accurate',\n",
       " 'efficient',\n",
       " 'reasoning',\n",
       " 'unsolved',\n",
       " 'problem']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "after_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a2abb0a3-87b3-4d38-add3-a47bacfde5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_content= ' ' .join(after_stopwords) # to convert the list into paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8443154d-dec4-4c6e-8d46-ad62cd831af0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Artificial intelligence AI capability computational systems perform tasks typically associated human intelligence learning reasoning problemsolving perception decisionmaking It field research computer science develops studies methods software enable machines perceive environment use learning intelligence take actions maximize chances achieving defined goals1 Highprofile applications AI include advanced web search engines eg Google Search recommendation systems used YouTube Amazon Netflix virtual assistants eg Google Assistant Siri Alexa autonomous vehicles eg Waymo generative creative tools eg language models AI art superhuman play analysis strategy games eg chess Go However many AI applications perceived AI A lot cutting edge AI filtered general applications often without called AI something becomes useful enough common enough labeled AI anymore23 Various subfields AI research centered around particular goals use particular tools The traditional goals AI research include learning reasoning knowledge representation planning natural language processing perception support roboticsa To reach goals AI researchers adapted integrated wide range techniques including search mathematical optimization formal logic artificial neural networks methods based statistics operations research economicsb AI also draws upon psychology linguistics philosophy neuroscience fields4 Some companies OpenAI Google DeepMind Meta5 aim create artificial general intelligence AGIâ€”AI complete virtually cognitive task least well human Artificial intelligence founded academic discipline 19566 field went multiple cycles optimism throughout history78 followed periods disappointment loss funding known AI winters910 Funding interest vastly increased 2012 graphics processing units started used accelerate neural networks deep learning outperformed previous AI techniques11 This growth accelerated 2017 transformer architecture12 In 2020s ongoing period rapid progress advanced generative AI became known AI boom Generative AIs ability create modify content led several unintended consequences harms raising ethical concerns AIs longterm effects potential existential risks prompting discussions regulatory policies ensure safety benefits technology Goals The general problem simulating creating intelligence broken subproblems These consist particular traits capabilities researchers expect intelligent system display The traits described received attention cover scope AI researcha Reasoning problemsolving Early researchers developed algorithms imitated stepbystep reasoning humans use solve puzzles make logical deductions13 By late 1980s 1990s methods developed dealing uncertain incomplete information employing concepts probability economics14 Many algorithms insufficient solving large reasoning problems experience combinatorial explosion They become exponentially slower problems grow15 Even humans rarely use stepbystep deduction early AI research could model They solve problems using fast intuitive judgments16 Accurate efficient reasoning unsolved problem'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "final_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50c6999-f7d3-4a59-b0f5-b028cdde9d44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fe68a4-10c5-45a2-9503-b305570a1ecc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34b1b0b-e6ee-4efb-9f5a-44a320217e30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "87dc9048-d3a1-40a8-8a8b-832050fb32ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# By using list comprehensions\n",
    "number=[2,3,4,5,6]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d9d10ae8-e19b-4bf6-80ec-2f53525f5420",
   "metadata": {},
   "outputs": [],
   "source": [
    "sq_list=[]\n",
    "for x in number:\n",
    "    sq=x**2\n",
    "    sq_list.append(sq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d9f4b454-27ee-4c29-bb90-fc0c93e095bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 9, 16, 25, 36]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sq_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bd86aa66-b892-4667-82b2-dc1b85bc64e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sq_list=[x**2 for x in number]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ac844a02-a1ae-466a-b422-95ed7588ee68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 9, 16, 25, 36]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sq_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f52fbbd8-12bc-4fcd-b9b5-da4b8e0f1d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_context1= [ ' ' for x in tokens] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7bb535d7-11a4-4e3f-bbd5-35b5d26d3a80",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_context1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "14393baa-87fd-4770-87e2-563f156921de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading spacy-3.8.7-cp312-cp312-win_amd64.whl.metadata (28 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Downloading murmurhash-1.0.13-cp312-cp312-win_amd64.whl.metadata (2.2 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "  Downloading cymem-2.0.11-cp312-cp312-win_amd64.whl.metadata (8.8 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
      "  Downloading preshed-3.0.10-cp312-cp312-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting thinc<8.4.0,>=8.3.4 (from spacy)\n",
      "  Downloading thinc-8.3.6-cp312-cp312-win_amd64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
      "  Downloading wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
      "  Downloading srsly-2.5.1-cp312-cp312-win_amd64.whl.metadata (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.1.0 (from spacy)\n",
      "  Downloading weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typer<1.0.0,>=0.3.0 (from spacy)\n",
      "  Downloading typer-0.16.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from spacy) (4.66.5)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from spacy) (1.26.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from spacy) (2.8.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\admin\\anaconda3\\lib\\site-packages (from spacy) (75.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from spacy) (24.1)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy)\n",
      "  Downloading langcodes-3.5.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Downloading language_data-1.3.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n",
      "Collecting blis<1.4.0,>=1.3.0 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Downloading blis-1.3.0-cp312-cp312-win_amd64.whl.metadata (7.6 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Downloading confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting numpy>=1.19.0 (from spacy)\n",
      "  Using cached numpy-2.3.1-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0.0,>=0.3.0->spacy)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.7.1)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Downloading cloudpathlib-0.21.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (5.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.1.3)\n",
      "Collecting marisa-trie>=1.1.0 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Downloading marisa_trie-1.2.1-cp312-cp312-win_amd64.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.0)\n",
      "Downloading spacy-3.8.7-cp312-cp312-win_amd64.whl (13.9 MB)\n",
      "   ---------------------------------------- 0.0/13.9 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/13.9 MB 3.4 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 1.6/13.9 MB 5.6 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 3.7/13.9 MB 7.3 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 5.2/13.9 MB 7.1 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 6.6/13.9 MB 7.1 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 8.1/13.9 MB 7.0 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 9.7/13.9 MB 7.0 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 11.3/13.9 MB 7.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 12.1/13.9 MB 6.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 13.1/13.9 MB 6.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  13.9/13.9 MB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  13.9/13.9 MB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  13.9/13.9 MB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  13.9/13.9 MB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 13.9/13.9 MB 4.7 MB/s eta 0:00:00\n",
      "Downloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.11-cp312-cp312-win_amd64.whl (39 kB)\n",
      "Downloading langcodes-3.5.0-py3-none-any.whl (182 kB)\n",
      "Downloading murmurhash-1.0.13-cp312-cp312-win_amd64.whl (24 kB)\n",
      "Downloading preshed-3.0.10-cp312-cp312-win_amd64.whl (116 kB)\n",
      "Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.5.1-cp312-cp312-win_amd64.whl (632 kB)\n",
      "   ---------------------------------------- 0.0/632.6 kB ? eta -:--:--\n",
      "   --------------------------------- ------ 524.3/632.6 kB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 632.6/632.6 kB 1.4 MB/s eta 0:00:00\n",
      "Downloading thinc-8.3.6-cp312-cp312-win_amd64.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ----------------- ---------------------- 0.8/1.7 MB 5.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.6/1.7 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 4.0 MB/s eta 0:00:00\n",
      "Using cached numpy-2.3.1-cp312-cp312-win_amd64.whl (12.7 MB)\n",
      "Downloading typer-0.16.0-py3-none-any.whl (46 kB)\n",
      "Downloading wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Downloading weasel-0.4.1-py3-none-any.whl (50 kB)\n",
      "Downloading blis-1.3.0-cp312-cp312-win_amd64.whl (6.3 MB)\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 1.0/6.3 MB 5.6 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 2.1/6.3 MB 5.3 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 3.4/6.3 MB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 4.5/6.3 MB 5.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 5.5/6.3 MB 5.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 6.0/6.3 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.3/6.3 MB 4.5 MB/s eta 0:00:00\n",
      "Downloading cloudpathlib-0.21.1-py3-none-any.whl (52 kB)\n",
      "Downloading confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Downloading language_data-1.3.0-py3-none-any.whl (5.4 MB)\n",
      "   ---------------------------------------- 0.0/5.4 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 1.0/5.4 MB 5.6 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 2.1/5.4 MB 5.6 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 3.4/5.4 MB 5.3 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 3.9/5.4 MB 4.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 5.0/5.4 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.4/5.4 MB 4.1 MB/s eta 0:00:00\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading marisa_trie-1.2.1-cp312-cp312-win_amd64.whl (150 kB)\n",
      "Installing collected packages: cymem, wasabi, spacy-loggers, spacy-legacy, shellingham, numpy, murmurhash, marisa-trie, cloudpathlib, catalogue, srsly, preshed, language-data, blis, typer, langcodes, confection, weasel, thinc, spacy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "Successfully installed blis-1.3.0 catalogue-2.0.10 cloudpathlib-0.21.1 confection-0.1.5 cymem-2.0.11 langcodes-3.5.0 language-data-1.3.0 marisa-trie-1.2.1 murmurhash-1.0.13 numpy-2.3.1 preshed-3.0.10 shellingham-1.5.4 spacy-3.8.7 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.5.1 thinc-8.3.6 typer-0.16.0 wasabi-1.1.3 weasel-0.4.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\~umpy'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "contourpy 1.2.0 requires numpy<2.0,>=1.20, but you have numpy 2.3.1 which is incompatible.\n",
      "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.3.1 which is incompatible.\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.1 which is incompatible.\n",
      "scipy 1.13.1 requires numpy<2.3,>=1.22.4, but you have numpy 2.3.1 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "be05e2f4-2637-440c-99f8-1f06037ed67a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 189, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 148, in _get_module_details\n",
      "  File \"<frozen runpy>\", line 112, in _get_module_details\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\spacy\\__init__.py\", line 6, in <module>\n",
      "    from .errors import setup_default_warnings\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\spacy\\errors.py\", line 3, in <module>\n",
      "    from .compat import Literal\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\spacy\\compat.py\", line 4, in <module>\n",
      "    from thinc.util import copy_array\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\thinc\\__init__.py\", line 5, in <module>\n",
      "    from .config import registry\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\thinc\\config.py\", line 5, in <module>\n",
      "    from .types import Decorator\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\thinc\\types.py\", line 27, in <module>\n",
      "    from .compat import cupy, has_cupy\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\thinc\\compat.py\", line 99, in <module>\n",
      "    import h5py\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\h5py\\__init__.py\", line 45, in <module>\n",
      "    from ._conv import register_converters as _register_converters, \\\n",
      "  File \"h5py\\\\_conv.pyx\", line 1, in init h5py._conv\n",
      "  File \"h5py\\\\h5r.pyx\", line 1, in init h5py.h5r\n",
      "  File \"h5py\\\\h5p.pyx\", line 1, in init h5py.h5p\n",
      "ValueError: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4719db5-9972-48d6-ae52-c32660291403",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pyton -m spacy download en_core_web_md => medium model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723d6ff7-9c9c-44db-909f-d418043857c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pyton -m spacy download en_core_web_lg => for large model  accuracy is high  but it takes high storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1bea0d48-e381-4107-91d6-f1e6f30966d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\admin\\anaconda3\\lib\\site-packages (2.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "36476d34-5d5c-4381-b7a2-b786d48864c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: h5py 3.11.0\n",
      "Uninstalling h5py-3.11.0:\n",
      "  Successfully uninstalled h5py-3.11.0\n",
      "Collecting h5py\n",
      "  Downloading h5py-3.14.0-cp312-cp312-win_amd64.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: numpy>=1.19.3 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from h5py) (2.3.1)\n",
      "Downloading h5py-3.14.0-cp312-cp312-win_amd64.whl (2.9 MB)\n",
      "   ---------------------------------------- 0.0/2.9 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.3/2.9 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.8/2.9 MB 2.6 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 2.1/2.9 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.9/2.9 MB 4.1 MB/s eta 0:00:00\n",
      "Installing collected packages: h5py\n",
      "Successfully installed h5py-3.14.0\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y h5py\n",
    "!pip install h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ed9ebb4d-8061-48d4-b248-70facdced4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.3/12.8 MB ? eta -:--:--\n",
      "     --- ------------------------------------ 1.0/12.8 MB 4.2 MB/s eta 0:00:03\n",
      "     --------- ------------------------------ 2.9/12.8 MB 6.0 MB/s eta 0:00:02\n",
      "     ------------- -------------------------- 4.5/12.8 MB 6.4 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.5/12.8 MB 6.1 MB/s eta 0:00:02\n",
      "     --------------------- ------------------ 6.8/12.8 MB 6.3 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 8.7/12.8 MB 6.5 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 9.7/12.8 MB 6.4 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 10.7/12.8 MB 6.2 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 12.3/12.8 MB 6.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.8/12.8 MB 6.1 MB/s eta 0:00:00\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.8.0\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8646fe01-8fb8-4241-81fa-83d1964ffdf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
